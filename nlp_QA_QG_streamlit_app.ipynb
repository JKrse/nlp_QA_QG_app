{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_QA_QG_streamlit_app.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UziPYW_xiiPW",
        "BYZ4fPN_nYXq",
        "o96ARPBqndDL",
        "sACGfYp_E9AP",
        "usv0XQOsItHp",
        "W1TWpgyqsFHa",
        "r0Oa01IgE1l3",
        "4Jfir_zoGPRc",
        "-Xdck__nF_FV",
        "Vy2WWJYjF6Wx",
        "BHHUtikn2feq"
      ],
      "authorship_tag": "ABX9TyOHsVT80OD8TebrBQp6o1v4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKrse/nlp_QA_QG_app/blob/multilingual/nlp_QA_QG_streamlit_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UziPYW_xiiPW",
        "colab_type": "text"
      },
      "source": [
        "# Streamlit demo for Question Answering & Question Generation\n",
        "\n",
        "Updated: 1st September 2020\n",
        "\n",
        "---\n",
        "\n",
        "This notebook enables you to run a streamlit app through a COLAB. As the demo includes a number of models used for Question Answering and Question Generation it can be somewhat storage and computational demanding, which you don't have to think about here!\n",
        "\n",
        "The final streamlit is essentially a combination of two seperate COLAB prototypes solving Question Answering and Question Generation respectively. These are now put together in a nice streamlit app with user interface. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYZ4fPN_nYXq",
        "colab_type": "text"
      },
      "source": [
        "##**Question Answering**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbaTzsOfnRL8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "- https://colab.research.google.com/drive/1s6WH45ZNSyM38FDcpqYfLXejDUDKTn5s?usp=sharing\n",
        "\n",
        "This is a prototype with various pre-trained NLP models for Questioning and Answering task.\n",
        "\n",
        "A pre-defined text snippet is defined in \"Text snippet - Data\", simple change input for new topic.\n",
        "\n",
        "Hugging Face models can be seen here (with the name of the pre-trained model): https://huggingface.co/transformers/pretrained_models.html\n",
        "\n",
        "It is very easy to add extra model, simple follow the pattern in the code and add the name to 'model' and 'user2model'.\n",
        "\n",
        "The pre-trained AllenNLP models found through the Usage: https://demo.allennlp.org/reading-comprehension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o96ARPBqndDL",
        "colab_type": "text"
      },
      "source": [
        "## **Question Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tuagnTlnLoW",
        "colab_type": "text"
      },
      "source": [
        "- https://colab.research.google.com/drive/1D5T4Y2AZapoeNeD9fNcX0hqNQ36Vg7Vp?usp=sharing\n",
        "\n",
        "**To get started simple collapse \"Demo for Question Generation\" and press run. Next open \"Main\" and run the script.**\n",
        "\n",
        "---\n",
        "\n",
        "The framework mimics ðŸ¤— transformers pipeline for easy inference\n",
        "\n",
        "**There are three pipeline tasks:** \n",
        "1. **question-generation: for single task question generation models**\n",
        "2. **multitask-qa-qg: for multi-task qa,qg models**\n",
        "3. **e2e-qg: for end-to-end question generation** \n",
        "\n",
        "With the option of using a model sizes \"small\" or a \"base\". All models are easily implemented but for this demo ***only the end-to-end question generation is included in this demo (both the small and base model)***. \n",
        "\n",
        "---\n",
        "This is a demo using patil-suraj work: https://github.com/patil-suraj/question_generation\n",
        "\n",
        "For fine-tuning the models please look at the git repository. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sACGfYp_E9AP",
        "colab_type": "text"
      },
      "source": [
        "# Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usv0XQOsItHp",
        "colab_type": "text"
      },
      "source": [
        "## Installing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGae1Lf9m7yT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "80a9dfda-cf2e-4465-dc5e-93dd33da37f8"
      },
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install gitpython\n",
        "!pip install nltk\n",
        "\n",
        "!pip install allennlp==1.0.0\n",
        "!pip install allennlp_models==1.0.0\n",
        "\n",
        "!pip install -U transformers==3.0.0\n",
        "\n",
        "!pip install langdetect"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/f2/03193332b9ced126141f095a7b0b75a1a5f43665aa1e4eb58d7cc0f69977/streamlit-0.66.0-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.2MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: botocore>=1.13.44 in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.17.48)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from streamlit) (0.10.1)\n",
            "Collecting enum-compat\n",
            "  Downloading https://files.pythonhosted.org/packages/55/ae/467bc4509246283bb59746e21a1a2f5a8aecbef56b1fa6eaca78cd438c8b/enum_compat-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (4.1.1)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.5.1)\n",
            "Collecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 45.8MB/s \n",
            "\u001b[?25hCollecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/41/4a/3360ff3cf2b4a1b9721ac1fbff5f84663f41047d9874b3aa1ac82e862c44/validators-0.18.1-py3-none-any.whl\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from streamlit) (0.14.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.14.48)\n",
            "Collecting watchdog\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (7.0.0)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/03/58572025c77b9e6027155b272a1b96298e711cd4f95c24967f7137ab0c4b/base58-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from streamlit) (2.8.1)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/1e/296f4108bf357e684617a776ecaf06ee93b43e30c35996dfac1aa985aa6c/pydeck-0.5.0b1-py2.py3-none-any.whl (4.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.4MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from streamlit) (20.4)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore>=1.13.44->streamlit) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore>=1.13.44->streamlit) (0.15.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore>=1.13.44->streamlit) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (2020.6.20)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->streamlit) (1.15.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (2.11.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (0.10.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->streamlit) (0.3.3)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/19/c2812690d8b340987eecd2cbc18549b1d130b94c5d97fcbe49f5f8710edf/ipykernel-5.3.4-py3-none-any.whl (120kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->streamlit) (49.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.7)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.6.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (19.0.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (2.1.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.1.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Building wheels for collected packages: blinker, watchdog, pathtools\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp36-none-any.whl size=13450 sha256=b44e3bf59bc2fb0231c2da420aa423cf707a20f77b5e3e5653c52366fb4a1491\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=502176ab55ff395d360a70f3f096d24a2b9c7548725db00b341d84719bf0fdb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=28f8679c9232c3f3f7e65bec10e8226b9316256768f2ea4b69b18f6ce88dc5ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built blinker watchdog pathtools\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: enum-compat, blinker, validators, pathtools, watchdog, base58, ipykernel, pydeck, streamlit\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed base58-2.0.1 blinker-1.4 enum-compat-0.0.3 ipykernel-5.3.4 pathtools-0.1.2 pydeck-0.5.0b1 streamlit-0.66.0 validators-0.18.1 watchdog-0.10.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4e/c050f5ed75f60cca4e9cc0a7056a9b424707a09f6293756e7dd19beb10db/pyngrok-4.1.12.tar.gz\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyngrok) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyngrok) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.12-cp36-none-any.whl size=16810 sha256=c50b626f22d2a66ff7545239fd12085175e3190eec53255b6b2def7c6db5dfea\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/c3/d6/6968dd4d831794d41c311be1d7af6f4ac151c5d3bd0e6efab8\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.12\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/bc/ae32e07e89cc25b9e5c793d19a1e5454d30a8e37d95040991160f942519e/GitPython-3.1.8-py3-none-any.whl (159kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 2.9MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 5.5MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.5 gitpython-3.1.8 smmap-3.0.4\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Collecting allennlp==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/49/bf0ec241496a82c9dd2f0b6ff6f8156b6b2b72b849df8c00a4f2bcf61485/allennlp-1.0.0-py3-none-any.whl (473kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481kB 3.0MB/s \n",
            "\u001b[?25hCollecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 317kB 13.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.14.48)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.4.1)\n",
            "Collecting torch<1.6.0,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 753.2MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.2.5)\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.0.12)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.22.2.post1)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/70/ed1ba808a87d896b9f4d25400dda54e089ca7a97e87cee620b3744997c89/jsonnet-0.16.0.tar.gz (256kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266kB 41.8MB/s \n",
            "\u001b[?25hCollecting overrides==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (4.41.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.2.4)\n",
            "Collecting transformers<2.12,>=2.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 675kB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (1.17.48)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.6.0,>=1.5.0->allennlp==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp==1.0.0) (1.7.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (8.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (20.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (49.6.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (1.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.2)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (2019.12.20)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 35.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 32.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->allennlp==1.0.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->allennlp==1.0.0) (0.15.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp==1.0.0) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0) (7.1.2)\n",
            "Building wheels for collected packages: jsonnet, overrides, sacremoses\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.16.0-cp36-cp36m-linux_x86_64.whl size=3321616 sha256=f459cd34a8e0c27cb83c74ecddf6114b2de7a8e19ea621ac8b6dc4b295476bf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/a9/43/bc5e0463deeec89dfca928a2a64595f1bdb520c891f6fbd09c\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=e95fc29f11912323bbbff5bc54e9d2c5719241f144ad9e27d6fc22eff6a1cbe5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=36806ea1ba00f17097d82e112c7f292f1f566e97151a03ef76bc19030e12a83d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built jsonnet overrides sacremoses\n",
            "\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 1.5.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboardX, torch, jsonpickle, jsonnet, overrides, sentencepiece, tokenizers, sacremoses, transformers, allennlp\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "Successfully installed allennlp-1.0.0 jsonnet-0.16.0 jsonpickle-1.4.1 overrides-3.0.0 sacremoses-0.0.43 sentencepiece-0.1.91 tensorboardX-2.1 tokenizers-0.7.0 torch-1.5.1 transformers-2.11.0\n",
            "Collecting allennlp_models==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d5/9ee1d0b8c217b6978e42e54fbab8bafe9e792f0f8262f381dde44cee44ae/allennlp_models-1.0.0-py3-none-any.whl (282kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 286kB 2.7MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Collecting py-rouge==1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/1d/0bdbaf559fb7afe32308ebc84a2028600988212d7eb7fb9f69c4e829e4a0/py_rouge-1.1-py3-none-any.whl (56kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp_models==1.0.0) (3.2.5)\n",
            "Requirement already satisfied: allennlp==1.0.0 in /usr/local/lib/python3.6/dist-packages (from allennlp_models==1.0.0) (1.0.0)\n",
            "Collecting conllu==3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/66/0b/a8863b5c14aee200a13a0f8c28550fd0132e947ae88441c9f517eb84613b/conllu-3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->allennlp_models==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (2.1)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (4.41.1)\n",
            "Requirement already satisfied: torch<1.6.0,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (1.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (3.6.4)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (2.2.4)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (1.14.48)\n",
            "Requirement already satisfied: overrides==3.0.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (3.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: transformers<2.12,>=2.9 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp_models==1.0.0) (2.11.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0->allennlp_models==1.0.0) (3.12.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp_models==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp_models==1.0.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp_models==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp_models==1.0.0) (2.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.6.0,>=1.5.0->allennlp==1.0.0->allennlp_models==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp==1.0.0->allennlp_models==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp_models==1.0.0) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp_models==1.0.0) (8.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp_models==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp_models==1.0.0) (49.6.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp_models==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp_models==1.0.0) (20.1.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp_models==1.0.0) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp_models==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp_models==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp_models==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp_models==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp_models==1.0.0) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp_models==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp_models==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp_models==1.0.0) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp==1.0.0->allennlp_models==1.0.0) (1.7.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0->allennlp_models==1.0.0) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0->allennlp_models==1.0.0) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0->allennlp_models==1.0.0) (1.17.48)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp_models==1.0.0) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp_models==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp_models==1.0.0) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp_models==1.0.0) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp_models==1.0.0) (20.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp==1.0.0->allennlp_models==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->allennlp==1.0.0->allennlp_models==1.0.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->allennlp==1.0.0->allennlp_models==1.0.0) (0.15.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0->allennlp_models==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp==1.0.0->allennlp_models==1.0.0) (2.4.7)\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=dce10fc7d11170e8ee6d1676d7fd3a8ae59d00dd783a106a43c6fb559a34c206\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number, py-rouge, conllu, allennlp-models\n",
            "Successfully installed allennlp-models-1.0.0 conllu-3.0 py-rouge-1.1 word2number-1.1\n",
            "Collecting transformers==3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 757kB 2.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 14.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "\u001b[31mERROR: allennlp 1.0.0 has requirement transformers<2.12,>=2.9, but you'll have transformers 3.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Found existing installation: tokenizers 0.7.0\n",
            "    Uninstalling tokenizers-0.7.0:\n",
            "      Successfully uninstalled tokenizers-0.7.0\n",
            "  Found existing installation: transformers 2.11.0\n",
            "    Uninstalling transformers-2.11.0:\n",
            "      Successfully uninstalled transformers-2.11.0\n",
            "Successfully installed tokenizers-0.8.0rc4 transformers-3.0.0\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 983kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=02ed750a697e111662b2500d50f4ce31a73117187211147b1c5638e67206928d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1TWpgyqsFHa",
        "colab_type": "text"
      },
      "source": [
        "## Clone Git\n",
        "The git for Question Generation is cloned for this COLAB. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98vcCWAysOeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import git\n",
        "if not os.path.exists(f\"{os.getcwd()}/question_generation/\"):\n",
        "    git.Git(os.getcwd()).clone(\"https://github.com/patil-suraj/question_generation.git\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0Oa01IgE1l3",
        "colab_type": "text"
      },
      "source": [
        "# Write App scripts\n",
        "Writing the python scripts used when running the app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jfir_zoGPRc",
        "colab_type": "text"
      },
      "source": [
        "### App"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gokXHP1NE028",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0065674d-4430-475d-c5be-db2b6db276f7"
      },
      "source": [
        "%%writefile app.py\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "import streamlit as st\n",
        "from screens import *\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "PAGE_CONFIG = {\"page_title\":\"QG_QA_demo.io\",\"page_icon\":\":shark:\",\"layout\":\"centered\"}\n",
        "st.beta_set_page_config(**PAGE_CONFIG)\n",
        "\n",
        "# App start: \n",
        "def main():\n",
        "    menu = [\"About\", \"Question Answering\", \"Question Generation\"]\n",
        "    choice = st.sidebar.selectbox(\"Menu\", menu)\n",
        "    \n",
        "    #===========================================================================\n",
        "    # Main Page: \n",
        "    if choice == \"About\":\n",
        "        main_screen()\n",
        "\n",
        "    #===========================================================================\n",
        "    # QA Page: \n",
        "    if choice == \"Question Answering\": \n",
        "        QA_screen()\n",
        "\n",
        "    #===========================================================================\n",
        "    # QG Page: \n",
        "    if choice == \"Question Generation\":\n",
        "        QG_screen()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xdck__nF_FV",
        "colab_type": "text"
      },
      "source": [
        "### Screens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZh3-TWzF-sX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "49e6f8ff-8869-4e95-bed6-eaead41a9a8c"
      },
      "source": [
        "%%writefile screens.py\n",
        "\n",
        "#===============================================================================\n",
        "import streamlit as st\n",
        "from functions import *\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import numpy as np\n",
        "#===============================================================================\n",
        "\n",
        "# Input variables  \n",
        "models_dict_qg = Config.models_qg\n",
        "models_dict_qa = Config.models_qa\n",
        "\n",
        "demo_text_qg = Config.demo_text_qg\n",
        "demo_text_qa = Config.demo_text_qa[\"context\"]\n",
        "demo_ques_qa = Config.demo_text_qa[\"question\"]\n",
        "\n",
        "language_lookup = Config.language_lookup\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "def QG_screen():\n",
        "    st.title(\"Question Generation\")\t\n",
        "    st.write(\"Question Generation (QG) aims to generate natural language, \"\\\n",
        "            \"questions based on given contents where the generated questions \"\\\n",
        "            \"need to be able to be answered by the contents.\")\n",
        "    #####################################\n",
        "    st.subheader(\"Model selection\")\n",
        "    #### Model select and user input ####\n",
        "    option_qg = st.selectbox(\"Select model size:\",\n",
        "                        (list(models_dict_qg.keys())))\n",
        "    st.subheader(\"Provide context\")\n",
        "    user_input_qg = st.text_area(\"Please provide context text:\", height=200,\n",
        "                                value=f\"{demo_text_qg}\", max_chars=500)\n",
        "    \n",
        "    ######################################\n",
        "    # List user context setence by setence\n",
        "    sentences_qg = sent_tokenize(user_input_qg)\n",
        "    list_context(\"Sentences\", sentences_qg)\n",
        "\n",
        "    ######################################\n",
        "    #### Load the NLP model: ####\n",
        "    nlp_qg  = modelsConfig_qg(option_qg)\n",
        "    questions = nlp_qg(user_input_qg)\n",
        "    \n",
        "    st.write(\"**Question Generated:**\")\n",
        "    for i, question in enumerate(questions):\n",
        "        st.write(f\"{i+1}. {question}\")\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "def QA_screen():\n",
        "    st.title(\"Question Answering\")\n",
        "    st.write(\"Reading comprehension is the task of answering questions about \"\\\n",
        "        \"a passage of text to show that the system understands the passage.\")\n",
        "    #####################################\n",
        "    #### Model select and user input ####\n",
        "    st.subheader(\"Model selection\")\n",
        "    option_qa = st.selectbox(\"Select model:\",\n",
        "        (list(models_dict_qa.keys())))\n",
        "    \n",
        "\n",
        "\n",
        "    st.subheader(\"Provide context:\")\n",
        "    user_context_qa = st.text_area(\"Please provide text:\", height=100,\n",
        "                                value=f\"{demo_text_qa}\", max_chars=500)\n",
        "    \n",
        "    #####################################\n",
        "    #### Context setence by setence ####\n",
        "    sentences_qa = sent_tokenize(user_context_qa)\n",
        "    list_context(\"Sentences\", sentences_qa, checkbox=True)\n",
        "    \n",
        "    st.subheader(\"Provide the question(s):\")\n",
        "    user_question_qa = st.text_area(\"Please provide question text:\", height=50,\n",
        "                                value=f\"{demo_ques_qa}\", max_chars=200)\n",
        "    \n",
        "\n",
        "    questions = sent_tokenize(user_question_qa)\n",
        "\n",
        "\n",
        "    #####################################\n",
        "    #### Load the NLP model ####\n",
        "    nlp_qa = modelsConfig_qa(option_qa)\n",
        "    \n",
        "    answers = {}\n",
        "    for i, question in enumerate(questions):\n",
        "        st.write(f\"{i+1}. **Question**: {question}\")\n",
        "        answer = qa_compute_answer(nlp_qa, questions[i], \n",
        "                                    user_context_qa, models_dict_qa[option_qa])\n",
        "        \n",
        "        answers[answer] = answer_index(answer, user_context_qa)\n",
        "        st.write(f\"{i+1}. **Answer**: {answer}\")\n",
        "\n",
        "\n",
        "    #####################################\n",
        "    #### Language detection ####\n",
        "    \n",
        "    if option_qa == \"mrm8488/bert-multi-cased-finetuned-xquadv1 [multilingual]\": \n",
        "        st.sidebar.markdown(\"**Note - This model is multilingual and support the following languages:**\")\n",
        "        st.sidebar.markdown(list(language_lookup.values()))\n",
        "        st.sidebar.markdown(\"\")\n",
        "        \n",
        "        st.sidebar.markdown(\"Context:\")\n",
        "        language_detect(user_context_qa,sidebar=True)\n",
        "        st.sidebar.markdown(\"Question:\")\n",
        "        language_detect(user_question_qa,sidebar=True)\n",
        "\n",
        "    #####################################\n",
        "    #### Highlight answer in context ####\n",
        "    st.subheader(\"Answer shown in context\")\n",
        "    num_answer = range(1, len(answers)+1)\n",
        "    \n",
        "    if len(num_answer) == 1: \n",
        "        index_range = answers[list(answers)[0]]\n",
        "        write_answer(user_context_qa, index_range)\n",
        "    \n",
        "    elif len(num_answer) > 1:\n",
        "        option_qa = st.selectbox(\"Select question in context:\", list(num_answer))\n",
        "        index_range = answers[list(answers)[option_qa-1]]\n",
        "        write_answer(user_context_qa, index_range)\n",
        "\n",
        "\n",
        "    #####################################\n",
        "    \n",
        "    \n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "def main_screen():\n",
        "    st.title(\"Question Answering & Question Generation\")\n",
        "    #####################################\n",
        "    st.subheader(\"About :trophy:\")\n",
        "    st.write(\"Hello there and welcome!\")\n",
        "    st.write(\"In this prototype you are able to play around with \"\\\n",
        "            \"state-of-the-art NLP models in an easy user friendly environment.\")\n",
        "    st.write(\"There are two main task, namely; Question Answering and Question \"\\\n",
        "            \"Generation. Use the sidebar to navigate to them respectively.\")\n",
        "    \n",
        "    #####################################\n",
        "    st.subheader(\"Github :zap:\")\n",
        "    st.write(\"You can find the git repository for the app here:\")\n",
        "    st.write(\"https://github.com/JKrse/nlp_streamlit_QG_QA\")\n",
        "\n",
        "    #####################################\n",
        "    st.subheader(\"COLAB :crocodile:\")\n",
        "    st.write(\"To play around with all of models can be both demanding in storage\"\\\n",
        "            \"(~6gb) and can be computationally. To cope with this a COLAB notebook has\"\\\n",
        "            \"been developed, which enables you to run the streamlit app through COLAB.\"\\\n",
        "            \"Models are now stored and computationen made on using Google service.\")\n",
        "    st.write(\"https://colab.research.google.com/drive/1zjWn1OEvL_OJxQufjCnrtIIq25qT9DMz?usp=sharing\")\n",
        "    st.write(\"Note you will need to modify the script a little bit by adding\"\\\n",
        "            \"your own ngrok to generate the localhost server.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting screens.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy2WWJYjF6Wx",
        "colab_type": "text"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei2UoRGdTX0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "96baf349-2adf-43ee-96ce-86167e8752ea"
      },
      "source": [
        "%%writefile functions.py\n",
        "\n",
        "#===============================================================================\n",
        "import streamlit as st\n",
        "\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "import allennlp_models.rc\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "import git\n",
        "import os\n",
        "if not os.path.exists(f\"{os.getcwd()}/question_generation/\"):\n",
        "    git.Git(os.getcwd()).clone(\"https://github.com/patil-suraj/question_generation.git\")\n",
        "\n",
        "from question_generation.pipelines import pipeline as qg_pipline\n",
        "from transformers import pipeline as qa_pipline\n",
        "\n",
        "#===============================================================================\n",
        "class Config:\n",
        "    models_qg = {\n",
        "        \"Question generation (without answer supervision) [small]\" : \"qg\",\n",
        "        \"Question generation (without answer supervision) [base]\" : \"qg\",\n",
        "    }\n",
        "    \n",
        "    models_qa = {\n",
        "        \"ELMo-BiDAF (Trained on SQuAD)\" : \"allennlp\",\n",
        "        \"BiDAG (Trained on SQuAD)\" : \"allennlp\",\n",
        "        # \"Transformer QA (Trained on SQuAD)\" : \"allennlp\", # not working [hack]\n",
        "        \"distilbert-base-cased-distilled-squad\" : \"huggingface_pipline\", \n",
        "        \"bert-large-uncased-whole-word-masking-finetuned-squad\"  : \"huggingface_pipline\",\n",
        "        # Multilingual:\n",
        "        \"mrm8488/bert-multi-cased-finetuned-xquadv1 [multilingual]\" : \"huggingface_pipline\",\n",
        "        }\n",
        "\n",
        "\n",
        "    demo_text_qg = \"Infosys Limited, is an Indian multinational corporation\" \\\n",
        "        \"that provides business consulting, information technology\" \\\n",
        "        \"and outsourcing services. The company is headquartered in\" \\\n",
        "        \"Bangalore, Karnataka, India. Infosys is the second-largest\" \\\n",
        "        \"Indian IT company after Tata Consultancy Services by 2017 revenue\" \\\n",
        "        \"figures and the 596th largest public company in the world based\" \\\n",
        "        \"on revenue. On 29 March 2019, its market capitalisation was $46.52 billion.\"\n",
        "\n",
        "\n",
        "    demo_text_qa = {\"context\" : \"Python is a programming language. Created by Guido van Rossum and first released in 1991.\",\n",
        "                    \"question\" : \"Who created Python? When was Python first released?\"}\n",
        "\n",
        "    language_lookup = {\n",
        "        \"ar\" : \"Arabic\",\n",
        "        \"de\" : \"German\",\n",
        "        \"el\" : \"Greek\",\n",
        "        \"en\" : \"English\",\n",
        "        \"es\" : \"Spanish\",\n",
        "        \"hi\" : \"Hindi\",\n",
        "        \"ru\" : \"Russian\",\n",
        "        \"th\" : \"Thai\",\n",
        "        \"tr\" : \"Turkish\",\n",
        "        \"vi\" : \"Vietnamese\",\n",
        "        \"zh\" : \"Chinese\"\n",
        "    }\n",
        "\n",
        "def list_context(title, list_input, checkbox = False):\n",
        "    \n",
        "    if checkbox:\n",
        "        checkbox_sent = st.checkbox(f\"Show {str(title).lower()}\")\n",
        "        \n",
        "        if checkbox_sent:\n",
        "            st.write(f\"**{title}:**\")\n",
        "            for sent in list_input:\n",
        "                st.write(f\"- {sent}\")\n",
        "    else: \n",
        "        st.write(f\"**{title}:**\")\n",
        "        for sent in list_input:\n",
        "            st.write(f\"- {sent}\")\n",
        "\n",
        "\n",
        "## Load model\n",
        "@st.cache\n",
        "def modelsConfig_qg(model):\n",
        "    ## Question Generation: \n",
        "    if model == \"Question generation (without answer supervision) [small]\":\n",
        "        model_selected = qg_pipline(\"e2e-qg\", model=\"valhalla/t5-small-e2e-qg\")\n",
        "    \n",
        "    elif model == \"Question generation (without answer supervision) [base]\":\n",
        "        model_selected = qg_pipline(\"e2e-qg\", model=\"valhalla/t5-base-e2e-qg\")    \n",
        "    \n",
        "    else:\n",
        "        raise Exception(\"Not a valid model\")   \n",
        "\n",
        "    return model_selected\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def modelsConfig_qa(model):\n",
        "    ## Question Answering: \n",
        "    if model == \"ELMo-BiDAF (Trained on SQuAD)\":\n",
        "        model_selected = Predictor.from_path(\n",
        "            \"https://storage.googleapis.com/allennlp-public-models/bidaf-elmo-model-2020.03.19.tar.gz\")\n",
        "    \n",
        "    elif model == \"BiDAG (Trained on SQuAD)\":\n",
        "        model_selected = Predictor.from_path(\n",
        "            \"https://storage.googleapis.com/allennlp-public-models/bidaf-model-2020.03.19.tar.gz\")\n",
        "    \n",
        "    elif model == \"Transformer QA (Trained on SQuAD)\":\n",
        "        model_selected = Predictor.from_path(\n",
        "            \"https://storage.googleapis.com/allennlp-public-models/transformer-qa-2020-05-26.tar.gz\")\n",
        "    \n",
        "    elif model == \"distilbert-base-cased-distilled-squad\":\n",
        "        model_selected = qa_pipline(\"question-answering\", model=f\"{model}\")\n",
        "    \n",
        "    elif model == \"bert-large-uncased-whole-word-masking-finetuned-squad\":\n",
        "        model_selected = qa_pipline(\"question-answering\", model=f\"{model}\")\n",
        "    \n",
        "    # Multilingual:\n",
        "    elif model == \"mrm8488/bert-multi-cased-finetuned-xquadv1 [multilingual]\":\n",
        "        model = \"mrm8488/bert-multi-cased-finetuned-xquadv1\"\n",
        "        model_selected = qa_pipline(\"question-answering\", model=f\"{model}\")\n",
        "    \n",
        "    else:\n",
        "        raise Exception(\"Not a valid model\")    \n",
        "    return model_selected\n",
        "\n",
        "\n",
        "\n",
        "def qa_compute_answer(model, question, context, model_library):\n",
        "    if model_library == \"allennlp\":\n",
        "        answer = predict_QnA_allennlp(question, context, model)[\"best_span_str\"]\n",
        "    \n",
        "    elif model_library == \"huggingface_pipline\":\n",
        "        answer = model(question=question, context=context)[\"answer\"]\n",
        "    return answer\n",
        "\n",
        "\n",
        "def predict_QnA_allennlp(question, passage, model): \n",
        "    ''' \n",
        "    Helper function for input convention used in hugging face implementation:\n",
        "        [QUESTION : ANSWER_TEXT]\n",
        "    '''\n",
        "    prediction = model.predict(passage=passage, question=question)\n",
        "    return prediction\n",
        "\n",
        "\n",
        "def answer_index(answer, context):\n",
        "    index_range = []\n",
        "    word_len = []    \n",
        "\n",
        "    for word in answer.split():\n",
        "        word.lower()\n",
        "        idx = context.find(word)\n",
        "        \n",
        "        word_len.append(len(word))    \n",
        "        index_range.append(idx)\n",
        "\n",
        "    index_range[-1]+word_len[-1]\n",
        "\n",
        "    answer_span = [index_range[0], index_range[-1]+word_len[-1]]\n",
        "\n",
        "    return answer_span\n",
        "\n",
        "\n",
        "def write_answer(context, answer_span):\n",
        "    st.write(f\"{context[0: answer_span[0]]}\"\\\n",
        "            f\"**{context[answer_span[0]: answer_span[1]]}**\"\n",
        "            f\"{context[answer_span[1]:]}\")    "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting functions.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOorJl4gJd0M",
        "colab_type": "text"
      },
      "source": [
        "# Connecting Streamlit app from COLAB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT_txREA2dC6",
        "colab_type": "text"
      },
      "source": [
        "## Your **ngrok** input - get Your Authentication Tokens\n",
        "First task is to signup to ngrok.com and create a free account. This will give you access to several features.\n",
        "\n",
        "To use ngrok,you will need to an authentication token which can be found on your dashboard of your ngrok account (https://dashboard.ngrok.com/get-started/setup).\n",
        "\n",
        "This is what you will use to authenticate when working with ngrok. You can find your authtokens below the â€˜Connect Your Accountâ€™ like this\n",
        "\n",
        "./ngrok authtokens xxxxxxxxxxxxxxxxxxxx\n",
        "\n",
        "This is what you will use to connect your account.\n",
        "\n",
        "Followed this guide for connection: https://blog.jcharistech.com/2020/08/16/how-to-run-streamlit-apps-from-googles-colab/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC-J4w2g-Rxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ngrok authtoken xxxxxxxxxxxxxxxxxxxx\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHHUtikn2feq",
        "colab_type": "text"
      },
      "source": [
        "##  Generate the proxy server!\n",
        "You are ready "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpLLxGzP-ucp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!streamlit run app.py &>/dev/null&\n",
        "from pyngrok import ngrok\n",
        "# Setup a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(port='8501')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3kXBr62-1Bm",
        "colab_type": "text"
      },
      "source": [
        "# Get your local server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb4vlzlS-_tI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75c29665-a107-42aa-ee66-1e72faed8e61"
      },
      "source": [
        "print(public_url)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://5bb19e934973.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}